{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidPredict_Pub.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqYrWpuFtp6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Covid predict program\n",
        "\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from shutil import copyfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHU0_llv8yQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/My Drive/CTImages.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "train_covid_dir = '/tmp/CTImages/Covid/'\n",
        "train_non_dir = '/tmp/CTImages/Non/'\n",
        "\n",
        "print(len(os.listdir(train_covid_dir)))\n",
        "print(len(os.listdir(train_non_dir)))\n",
        "\n",
        "# Expected Output for 15/04/2020:\n",
        "# 397\n",
        "# 397"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Wq5HlJ9jyV",
        "colab_type": "text"
      },
      "source": [
        "### Training and validation folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se76FhuJ9mkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  os.mkdir('/tmp/Covid-v-Non')\n",
        "  os.mkdir('/tmp/Covid-v-Non/training')\n",
        "  os.mkdir('/tmp/Covid-v-Non/validation')\n",
        "  os.mkdir('/tmp/Covid-v-Non/training/Covid')\n",
        "  os.mkdir('/tmp/Covid-v-Non/training/Non')\n",
        "  os.mkdir('/tmp/Covid-v-Non/validation/Covid')\n",
        "  os.mkdir('/tmp/Covid-v-Non/validation/Non')\n",
        "except OSError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtrJL_bf95eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3-FHyJ999Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "COVID_SOURCE_DIR = \"/tmp/CTImages/Covid/\"       # train_covid_dir\n",
        "TRAINING_COVID_DIR = \"/tmp/Covid-v-Non/training/Covid/\"\n",
        "VALIDATION_COVID_DIR = \"/tmp/Covid-v-Non/validation/Covid/\"\n",
        "\n",
        "NON_SOURCE_DIR = \"/tmp/CTImages/Non/\"           # train_non_dir\n",
        "TRAINING_NON_DIR = \"/tmp/Covid-v-Non/training/Non/\"\n",
        "VALIDATION_NON_DIR = \"/tmp/Covid-v-Non/validation/Non/\"\n",
        "\n",
        "split_size = .73\n",
        "split_data(COVID_SOURCE_DIR, TRAINING_COVID_DIR, VALIDATION_COVID_DIR, split_size)\n",
        "split_data(NON_SOURCE_DIR, TRAINING_NON_DIR, VALIDATION_NON_DIR, split_size)\n",
        "\n",
        "print(len(os.listdir('/tmp/Covid-v-Non/training/Covid/')))\n",
        "print(len(os.listdir('/tmp/Covid-v-Non/training/Non/')))\n",
        "\n",
        "print(len(os.listdir('/tmp/Covid-v-Non/validation/Covid/')))\n",
        "print(len(os.listdir('/tmp/Covid-v-Non/validation/Non/')))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOBZGEE--Xtn",
        "colab_type": "text"
      },
      "source": [
        "*texte en italique*# Download Model : MobileNetV2 or NAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXyqU3Yx-XS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet121\n",
        "\n",
        "IMG_SIZE = 224 # All images will be resized to 150x150\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# raises ValueError\n",
        "try:\n",
        "  pre_trained_model = DenseNet121(input_shape=IMG_SHAPE, include_top=False)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBxh3e9cAlPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('relu')\n",
        "#last_layer = pre_trained_model.get_layer('block_6_project_BN')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5GjIaoGAscw",
        "colab_type": "text"
      },
      "source": [
        "### *Prepare trainig*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZsY9Y64AySA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_dir = '/tmp/Covid-v-Non/training'\n",
        "validation_dir = '/tmp/Covid-v-Non/validation'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFkEJogLA9bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "# ---------------------- \n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=20,  # 500\\20   images = batch_size * steps\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=10,  #50\\10    images = batch_size * steps\n",
        "      verbose=2,\n",
        "      callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8B906MlDgbh",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy and Loss for the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P5DviuUDi7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc      = history.history[     'accuracy' ]\n",
        "val_acc  = history.history[ 'val_accuracy' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "\n",
        "plt.plot  ( epochs,     acc )\n",
        "plt.plot  ( epochs, val_acc )\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.plot  ( epochs,     loss )\n",
        "plt.plot  ( epochs, val_loss )\n",
        "plt.title ('Training and validation loss'   )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}